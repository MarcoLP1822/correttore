# üìã Piano di Implementazione Sistema Report Avanzato

**Data**: 24 Ottobre 2025  
**Obiettivo**: Implementare un sistema di report completo simile a Corrige.it con analisi ortografica e leggibilit√† avanzata

---

## üìä Analisi Sistema Corrige.it

### Funzionalit√† Chiave Identificate

#### 1. **Pagina Sintesi**
- Tabella principale divisa in due sezioni:
  - **Segnalazioni di correzione** (errori veri): Errori riconosciuti (X), Sconosciute (?), Sospette (!), Migliorabili (√¶), Punteggiatura (;)
  - **Segnalazioni d'informazione** (non errori): Imbarazzanti (¬ø), Varianti (‚âà), Nomi/sigle (N), Lingue (L), Con altre informazioni (‚ìò), Link (@)
- Contatori: Parole e Contesti per ogni categoria
- Metadati: Tempo elaborazione, parole/contesti verificati, nodo cloud, sistema
- Tabs navigazione: Sintesi, Ortografia, Ipertesto, Leggibilit√†, Leggibilit√† CT, Scarica...

#### 2. **Tab Errori Riconosciuti**
- Lista errori raggruppati per tipo (es: "affinch√©" con accento acuto)
- Mostra contesto completo con parola evidenziata in grassetto
- Pulsanti interattivi: "Corretta" o "Errore" per feedback
- Info aggiuntiva e suggerimenti
- Possibilit√† di segnalare alla redazione

#### 3. **Tab Sconosciute**
- Parole non nel database ma potenzialmente valide
- Liste alfabetiche con esempi di contesto
- Sistema di feedback per ogni occorrenza
- Database di milioni di parole

#### 4. **Tab Sospette**
- Parole corrette ma contestualmente sospette
- Lista suggerimenti alternativi in sfondo giallo
- Contesto completo per valutazione
- Esempi: "a √¨" vs "ai", "abbattuta" vs "imbattuta"

#### 5. **Tab Migliorabili**
- Espressioni migliorabili secondo norme redazionali
- Sfondo verde per distinguere da errori
- Suggerimenti di miglioramento (es: "ad" ‚Üí "a", "degli dei" ‚Üí "dei")
- Focus su stile e professionalit√†

#### 6. **Tab Punteggiatura**
- Errori di punteggiatura classificati per tipo
- Esempi numerati con descrizioni specifiche
- Sfondo giallo per evidenziazione
- Regole tipografiche dettagliate

#### 7. **Tab Imbarazzanti**
- Parole valide ma potenzialmente imbarazzanti/volgari
- Indicazione puramente linguistica
- Lista completa occorrenze con contesto
- Nessun giudizio sul contenuto

#### 8. **Tab Nomi/Sigle**
- Nomi propri, sigle, acronimi riconosciuti
- Liste alfabetiche ordinate
- Contesto di utilizzo
- Gestione omografi comuni

#### 9. **Report Leggibilit√†**
- Analisi GULPEASE frase per frase
- Confronto con Vocabolario di Base
- Lemmatizzazione automatica
- Dati sintetici e analitici
- Lista parole difficili
- Riconoscimento terminologia tecnico-scientifica

---

## üéØ Piano di Implementazione

### **FASE 1: Sistema di Tracking Correzioni** ‚≠ê Priorit√† ALTA

#### 1.1 Modello Dati per Classificazione Errori

**File**: `src/correttore/models/correction_tracking.py`

**Categorie da implementare**:
```python
class CorrectionCategory(Enum):
    ERRORI_RICONOSCIUTI = "X"      # Errori ortografici/grammaticali certi
    SCONOSCIUTE = "?"               # Parole non nel database
    SOSPETTE = "!"                  # Parole corrette ma sospette nel contesto
    MIGLIORABILI = "√¶"              # Espressioni migliorabili per stile
    PUNTEGGIATURA = ";"             # Errori di punteggiatura
    IMBARAZZANTI = "¬ø"              # Parole potenzialmente imbarazzanti
    VARIANTI = "‚âà"                  # Forme alternative accettabili
    NOMI_SIGLE = "N"                # Nomi propri, acronimi
    LINGUE = "L"                    # Parole in altre lingue
    CON_INFO = "‚ìò"                  # Segnalazioni con informazioni aggiuntive
```

**Struttura dati**:
```python
@dataclass
class CorrectionRecord:
    """Record dettagliato di una correzione"""
    id: str                         # ID univoco
    category: CorrectionCategory    # Categoria errore
    original_text: str              # Testo originale
    corrected_text: str            # Testo corretto (se applicabile)
    context: str                    # Contesto (frase completa)
    position: int                   # Offset carattere nel documento
    paragraph_index: int            # Indice paragrafo
    sentence_index: int             # Indice frase
    source: str                     # Fonte (LanguageTool, GPT, Custom)
    confidence_score: float         # Punteggio confidenza
    rule_id: str                    # ID regola che ha triggato
    message: str                    # Messaggio descrittivo
    suggestions: List[str]          # Suggerimenti alternativi
    timestamp: datetime             # Timestamp elaborazione
```

#### 1.2 Sistema di Logging Dettagliato

**Modifiche ai componenti esistenti**:

1. **LanguageTool Service** (`src/correttore/services/languagetool_service.py`)
   - Tracciare ogni match con categoria
   - Estrarre contesto completo
   - Classificare per tipo di errore

2. **OpenAI Service** (`src/correttore/services/openai_service.py`)
   - Loggare tutte le correzioni suggerite
   - Tracciare reasoning di GPT
   - Classificare suggerimenti

3. **Safe Correction Engine** (`src/correttore/core/safe_correction.py`)
   - Registrare decisioni (accettata/rifiutata)
   - Tracciare score breakdown
   - Mantenere storia completa

4. **Correction Engine** (`src/correttore/core/correction_engine.py`)
   - Aggregare tutti i tracking records
   - Generare statistiche globali
   - Preparare dati per report

#### 1.3 Collector Centralizzato

**File**: `src/correttore/core/correction_collector.py`

```python
class CorrectionCollector:
    """Raccoglie e organizza tutte le correzioni per il report"""
    
    def add_correction(self, record: CorrectionRecord)
    def get_by_category(self, category: CorrectionCategory) -> List[CorrectionRecord]
    def get_statistics(self) -> Dict[str, int]
    def get_by_word(self) -> Dict[str, List[CorrectionRecord]]
    def export_for_report(self) -> Dict
```

---

### **FASE 2: Report HTML Interattivo - Ortografia** ‚≠ê Priorit√† ALTA

#### 2.1 Generatore Report HTML

**File**: `src/correttore/utils/html_report_generator.py`

**Componenti**:
- Template HTML/CSS responsive
- JavaScript per navigazione tabs
- Codifica colori per categorie
- Esportazione standalone (HTML completo)

**Template Structure**:
```
templates/
‚îú‚îÄ‚îÄ report_base.html           # Template base
‚îú‚îÄ‚îÄ report_sintesi.html        # Tab sintesi
‚îú‚îÄ‚îÄ report_categoria.html      # Template generico per tabs
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îú‚îÄ‚îÄ report.css            # Stili CSS
‚îÇ   ‚îî‚îÄ‚îÄ report.js             # JavaScript interattivo
```

#### 2.2 Pagina Sintesi

**Elementi da implementare**:
1. **Tabella Riassuntiva**
   - Due colonne: Segnalazioni di correzione | Segnalazioni d'informazione
   - Icone per ogni categoria
   - Contatori: Parole uniche e Contesti totali
   - Totali per sezione

2. **Metadati Elaborazione**
   - Tempo di elaborazione
   - Parole totali / Contesti verificati
   - Sistema e versione
   - Timestamp

3. **Navigazione Tabs**
   - Tab dinamiche basate su categorie presenti
   - Highlight tab attiva
   - Badge con contatori

4. **Grafici Visualizzazione**
   - Grafico a torta distribuzione errori
   - Barre confronto categorie
   - Timeline elaborazione (opzionale)

#### 2.3 Tabs per Categoria di Errore

**Struttura Comune**:
1. **Header Tab**
   - Titolo con icona categoria
   - Descrizione categoria
   - Info box con spiegazioni e consigli

2. **Lista Errori**
   - Raggruppamento per tipo/parola
   - Intestazione gruppo con suggerimento
   - Espandibile/collassabile

3. **Occorrenze**
   - Contesto completo evidenziato
   - Parola originale in grassetto
   - Posizione nel documento
   - Pulsanti azione (futuro)

**Codifica Colori**:
- üî¥ Rosso: Errori riconosciuti
- üü° Giallo: Sconosciute, Sospette, Punteggiatura
- üü¢ Verde: Migliorabili
- ‚ö™ Bianco: Informazioni (Imbarazzanti, Nomi, ecc.)

#### 2.4 Esportazione Report

**Formati supportati**:
- HTML standalone (tutto in un file)
- HTML + assets separati
- PDF (opzionale, usando weasyprint)
- JSON (dati raw per analisi)

---

### **FASE 3: Analisi Leggibilit√† Frase per Frase** ‚úÖ **COMPLETATA** (25/10/2025)

> **Stato**: ‚úÖ Implementata e testata con successo  
> **Documentazione**: Vedi `docs/FASE3_COMPLETATA.md`  
> **File implementati**:
> - `src/correttore/utils/readability.py` (Esteso con SentenceReadability)
> - `src/correttore/utils/readability_report_generator.py` (Nuovo)
> - `test_readability_phase3.py` (Test suite completa)
> - `esempio_fase3.py` (Esempi di utilizzo)

#### 3.1 Estensione ReadabilityAnalyzer ‚úÖ

**File**: `src/correttore/utils/readability.py`

**Funzionalit√† implementate**:

```python
@dataclass
class SentenceReadability:
    """Analisi leggibilit√† singola frase"""
    text: str
    gulpease_score: float
    difficulty_level: str  # facile/media/difficile
    word_count: int
    letter_count: int
    sentence_index: int
    words_not_in_vdb: List[str]
    technical_terms: List[str]  # futuro
    
    def get_difficulty_color() -> str
    def get_difficulty_emoji() -> str
    
class ReadabilityAnalyzer:
    def split_into_sentences(self, text: str) -> List[str]
    def analyze_by_sentence(self, text: str, vocabulary_service=None) -> List[SentenceReadability]
    def get_difficult_sentences(self, sentences: List[SentenceReadability], threshold: float = 60) -> List[SentenceReadability]
    def get_sentence_statistics(self, sentences: List[SentenceReadability]) -> Dict[str, Any]
```

**Segmentazione Frasi**: ‚úÖ
- Gestisce abbreviazioni comuni (dott., prof., ecc.)
- Rispetta punteggiatura italiana
- Pattern regex ottimizzato

**Classificazione Difficolt√†**: ‚úÖ
- üìó **80-100**: Molto facile (verde scuro #2d5016)
- üìò **60-79**: Facile (verde chiaro #4a7c2c)
- üìô **40-59**: Difficile (giallo #f39c12)
- üìï **0-39**: Molto difficile (rosso #c0392b)

#### 3.2 Report Leggibilit√† HTML ‚úÖ

**File**: `src/correttore/utils/readability_report_generator.py`

**Classe implementata**: `ReadabilityReportGenerator`

**Struttura Report**:

1. **Sezione Sintesi** ‚úÖ
   - GULPEASE globale (grande e colorato)
   - Distribuzione difficolt√† (grafico a barre)
   - Statistiche generali:
     * Parole totali
     * Frasi totali
     * Lunghezza media frase
     * Parole/frase media
   - Quick stats:
     * Frasi facili / difficili / molto difficili
     * Distribuzione percentuale
   - Interpretazione per scolarizzazione (tabella)

2. **Sezione Analitica - Frase per Frase** ‚úÖ
   - Tabella interattiva con tutte le frasi
   - Colonne:
     * # Frase
     * Testo frase (con parole difficili evidenziate)
     * GULPEASE (colorato con emoji)
     * Difficolt√† (badge)
     * Parole totali
     * Parole non-VdB
   - Ordinamento: clic su header colonna
   - Filtri: Tutte / Facili / Difficili / Molto Difficili
   - Evidenziazione parole non nel VdB

3. **Sezione Vocabolario** ‚úÖ
   - Lista parole NON nel VdB
   - Frequenza di utilizzo
   - Statistiche copertura VdB
   - Info box esplicativo VdB
   - Top 50 parole per frequenza

4. **Visualizzazioni** ‚úÖ
   - Grafico a torta: distribuzione difficolt√†
   - Grafico linea: GULPEASE lungo il documento
   - Heatmap leggibilit√† (griglia colorata)
   - Canvas-based rendering (no librerie esterne)

**Caratteristiche**:
- ‚úÖ HTML standalone completo (CSS e JS embedded)
- ‚úÖ Design responsive mobile-first
- ‚úÖ Navigazione a tab
- ‚úÖ Animazioni smooth
- ‚úÖ Sorting e filtering interattivi
- ‚úÖ ~45KB per report tipico

**API Semplificata**:
```python
generate_readability_report(
    text: str,
    output_path: str,
    vocabulary_service: Optional = None,
    document_title: str = "Documento"
) -> str
```

---

### **FASE 4: Integrazione Vocabolario Base Avanzata** üî∏ Priorit√† MEDIA

#### 4.1 Analisi Parola per Parola

**Miglioramenti a VocabularyService** (`src/correttore/services/vocabulary_service.py`):

```python
@dataclass
class WordAnalysis:
    """Analisi dettagliata parola"""
    word: str
    in_vdb: bool
    level: str  # fondamentale, alto_uso, alta_disponibilit√†, fuori_vdb
    difficulty_score: float
    lemma: str  # forma base (con lemmatizzazione)
    is_technical: bool  # termine tecnico riconosciuto
    suggested_alternatives: List[str]  # alternative pi√π semplici
    
class VocabularyService:
    def analyze_word_detailed(self, word: str) -> WordAnalysis
    def suggest_simpler_alternatives(self, word: str) -> List[str]
    def classify_technical_terms(self, words: List[str]) -> List[str]
```

#### 4.2 Report Vocabolario nel Report Leggibilit√†

**Elementi da aggiungere**:
1. **Lista Parole Difficili**
   - Ordinate per frequenza
   - Con contesto
   - Suggerimenti alternativi
   
2. **Lista Termini Tecnici** (Leggibilit√† CT)
   - Parole tecniche legittime
   - Classificazione per dominio
   - Glossario automatico

3. **Statistiche Avanzate**
   - % Parole fondamentali
   - % Parole alto uso
   - % Parole alta disponibilit√†
   - % Parole fuori VdB

#### 4.3 Integrazione nel Workflow Correzione

**Modifiche a SafeCorrection** (`src/correttore/core/safe_correction.py`):

- **Validazione con VdB**: Parola nel VdB = probabile correttezza (+0.1 al score)
- **Penalit√† parole rare**: Correzione che introduce parola fuori VdB = penalit√† (-0.05)
- **Preferenza semplicit√†**: A parit√† di correttezza, preferire parole nel VdB

---

### **FASE 5: Lemmatizzazione con spaCy** üî∏ Priorit√† MEDIA

#### 5.1 Setup spaCy per Italiano

**Installazione**:
```bash
pip install spacy
python -m spacy download it_core_news_lg
```

**File**: `src/correttore/services/lemmatization_service.py`

```python
class LemmatizationService:
    """Servizio di lemmatizzazione per italiano"""
    
    def __init__(self):
        self.nlp = spacy.load("it_core_news_lg")
        
    def lemmatize(self, text: str) -> List[Tuple[str, str]]:
        """Returns list of (word, lemma) tuples"""
        
    def lemmatize_word(self, word: str) -> str:
        """Returns lemma of single word"""
        
    def get_pos_tags(self, text: str) -> List[Tuple[str, str]]:
        """Returns (word, POS_tag) tuples"""
```

#### 5.2 Integrazione con VocabularyService

**Confronto Intelligente**:
- "mangiato", "mangiando", "mangiai" ‚Üí tutti riconosciuti come "mangiare"
- Confronto con VdB sulla forma lemmatizzata
- Riduzione drastica falsi positivi
- Maggiore precisione analisi

**Esempio**:
```python
# Prima (senza lemmatizzazione)
is_in_vdb("mangiato")  # False (se solo "mangiare" √® nel VdB)

# Dopo (con lemmatizzazione)
lemma = lemmatize("mangiato")  # "mangiare"
is_in_vdb(lemma)  # True
```

#### 5.3 Named Entity Recognition (NER)

**Riconoscimento Automatico**:
- Persone (PER)
- Luoghi (LOC)
- Organizzazioni (ORG)
- Date/Numeri (DATE, CARDINAL)
- Eventi (EVENT)

**Utilizzo nel Report**:
- Tab "Nomi/sigle" popolata automaticamente
- Riduzione segnalazioni false per nomi propri
- Classificazione intelligente

---

### **FASE 6: Sistema Feedback e Apprendimento** üîπ Priorit√† BASSA

#### 6.1 Pulsanti Interattivi nel Report HTML

**Implementazione JavaScript**:
```javascript
// Per ogni segnalazione
<button class="btn-corretta" data-id="{{id}}">Corretta</button>
<button class="btn-errore" data-id="{{id}}">Errore</button>

// Salvataggio feedback via AJAX
function saveFeedback(id, tipo) {
    // POST a endpoint Flask
    fetch('/api/feedback', {
        method: 'POST',
        body: JSON.stringify({id: id, feedback: tipo})
    })
}
```

**Backend Flask** (`src/correttore/interfaces/web_interface.py`):
```python
@app.route('/api/feedback', methods=['POST'])
def save_feedback():
    # Salva feedback in database locale
    # Aggiorna dizionario custom se necessario
    # Return success
```

#### 6.2 Database Feedback

**File**: `data/feedback.db` (SQLite)

**Schema**:
```sql
CREATE TABLE feedback (
    id INTEGER PRIMARY KEY,
    correction_id TEXT,
    original_text TEXT,
    corrected_text TEXT,
    category TEXT,
    feedback TEXT,  -- 'corretta' o 'errore'
    timestamp DATETIME,
    document_name TEXT
);
```

#### 6.3 Apprendimento Automatico

**Logica**:
1. Se feedback "corretta" > 3 volte ‚Üí aggiungi a dizionario custom come "valida"
2. Se feedback "errore" > 3 volte ‚Üí aggiungi come correzione da applicare
3. Aggiornamento automatico `data/custom_corrections.txt`

#### 6.4 Dashboard Statistiche

**Nuova pagina web**: `/dashboard/feedback`

**Visualizzazioni**:
- Feedback totali ricevuti
- Pattern errori pi√π comuni
- Correzioni pi√π contestate
- Timeline miglioramenti
- Export dati per analisi

---

### **FASE 7: Categorie Speciali** üîπ Priorit√† BASSA

#### 7.1 Rilevamento Nomi Propri

**Usando spaCy NER**:
```python
def detect_proper_nouns(text: str) -> List[Dict]:
    doc = nlp(text)
    entities = []
    for ent in doc.ents:
        if ent.label_ in ["PER", "LOC", "ORG"]:
            entities.append({
                'text': ent.text,
                'label': ent.label_,
                'context': ent.sent.text
            })
    return entities
```

**Tab Report "Nomi/Sigle"**:
- Automaticamente popolata
- Classificazione per tipo (Persona, Luogo, Org)
- Ordine alfabetico
- Contesti di utilizzo

#### 7.2 Rilevamento Parole Straniere

**File**: `data/foreign_words/common_foreign.json`

**Dizionari per lingua**:
- Inglese: business, meeting, report, ecc.
- Latino: ad hoc, in primis, de facto, ecc.
- Francese: boutique, d√©j√† vu, ecc.

**Riconoscimento Automatico**:
- Pattern matching dizionario
- spaCy language detection (se disponibile)
- Heuristic: maiuscole, suffissi tipici

**Tab Report "Lingue"**:
- Lista parole straniere per lingua
- Suggerimento: tradurre o lasciare
- Contesto di utilizzo

#### 7.3 Lista Parole Imbarazzanti

**File**: `data/sensitive_words/imbarazzanti.json`

**Categorie**:
- Anatomia
- Termini volgari
- Doppi sensi comuni
- Termini sensibili

**Importante**:
- Nessun giudizio morale
- Puramente informativo
- Pu√≤ essere disabilitato
- Utile per testi pubblici/professionali

**Tab Report "Imbarazzanti"**:
- Lista neutra
- Contesto completo
- Info: "Indicazione puramente linguistica"
- Nessun colore allarmante

---

## üìÖ Roadmap Implementazione

### **Sprint 1: MVP Report Ortografia** (1-2 settimane)

**Obiettivo**: Report HTML funzionante con analisi base

**Deliverables**:
- ‚úÖ Sistema tracking correzioni (`CorrectionCollector`)
- ‚úÖ Modello dati (`CorrectionRecord`, `CorrectionCategory`)
- ‚úÖ Integrazione tracking in LanguageTool e OpenAI services
- ‚úÖ Generatore report HTML base
- ‚úÖ Template pagina Sintesi
- ‚úÖ Template Tab "Errori Riconosciuti"
- ‚úÖ Template Tab "Sconosciute"
- ‚úÖ CSS responsive con codifica colori
- ‚úÖ Export report HTML standalone

**Test**:
- Report generato per documento di test
- Tutte le categorie visualizzate correttamente
- Navigazione tabs funzionante
- Export HTML completo

---

### **Sprint 2: Leggibilit√† Avanzata** (1 settimana)

**Obiettivo**: Analisi leggibilit√† frase per frase con report HTML

**Deliverables**:
- ‚úÖ Estensione `ReadabilityAnalyzer` con analisi per frase
- ‚úÖ Segmentazione frasi con spaCy
- ‚úÖ Calcolo GULPEASE individuale
- ‚úÖ Classificazione difficolt√† frasi
- ‚úÖ Generatore report leggibilit√† HTML
- ‚úÖ Sezione Sintesi con grafici
- ‚úÖ Sezione Analitica frase per frase
- ‚úÖ Integrazione VdB nel report
- ‚úÖ Lista parole difficili

**Test**:
- Analisi corretta 100+ frasi
- Report leggibilit√† generato
- Codifica colori funzionante
- Statistiche accurate

---

### **Sprint 3: Raffinamenti e Categorie** (1 settimana)

**Obiettivo**: Completare tutte le categorie e migliorare precisione

**Deliverables**:
- ‚úÖ Tabs complete: Sospette, Migliorabili, Punteggiatura
- ‚úÖ Installazione e setup spaCy
- ‚úÖ Servizio lemmatizzazione
- ‚úÖ Integrazione lemmatizzazione in VocabularyService
- ‚úÖ Miglioramento confronto VdB
- ‚úÖ Riduzione falsi positivi
- ‚úÖ Ottimizzazione performance (caching)
- ‚úÖ Documentazione utente

**Test**:
- Confronto VdB con lemmatizzazione
- Performance < 5 secondi per 10k parole
- Report completo tutte categorie
- Accuracy migliorata 20%+

---

### **Sprint 4: Features Avanzate** (opzionale, 1-2 settimane)

**Obiettivo**: Sistema feedback, NER, categorie speciali

**Deliverables**:
- ‚úÖ Pulsanti feedback interattivi
- ‚úÖ Backend API feedback
- ‚úÖ Database SQLite feedback
- ‚úÖ Apprendimento automatico
- ‚úÖ NER con spaCy per nomi propri
- ‚úÖ Rilevamento parole straniere
- ‚úÖ Lista parole imbarazzanti
- ‚úÖ Tab complete: Nomi/Sigle, Lingue, Imbarazzanti
- ‚úÖ Dashboard statistiche
- ‚úÖ Export dati analitici JSON

**Test**:
- Feedback salvato correttamente
- Dizionario custom aggiornato automaticamente
- NER accurato >90%
- Dashboard funzionante

---

## üõ†Ô∏è Stack Tecnologico

### Python Libraries
```bash
# Gi√† installate
openai
python-docx
flask
pyyaml

# Nuove da installare
spacy                    # NLP, lemmatizzazione, NER
jinja2                   # Template HTML
plotly                   # Grafici interattivi (opzionale)
weasyprint              # Export PDF (opzionale)
```

### Frontend
- **HTML5/CSS3**: Struttura e stili
- **JavaScript (Vanilla)**: Interattivit√† tabs e feedback
- **Chart.js**: Grafici (alternativa leggera a Plotly)
- **Bootstrap** (opzionale): Grid e componenti UI

### Storage
- **SQLite**: Database feedback e statistiche
- **JSON**: Export dati, configurazioni

---

## üìÇ Struttura File da Creare

```
src/correttore/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ correction_tracking.py       # Nuovi modelli dati
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ correction_collector.py      # Collector centralizzato
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ lemmatization_service.py     # Servizio lemmatizzazione
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ html_report_generator.py     # Report ortografia HTML
‚îÇ   ‚îî‚îÄ‚îÄ readability_report_generator.py  # Report leggibilit√† HTML
‚îî‚îÄ‚îÄ interfaces/
    ‚îî‚îÄ‚îÄ web_interface.py              # Aggiungere endpoint feedback

templates/
‚îú‚îÄ‚îÄ report/
‚îÇ   ‚îú‚îÄ‚îÄ base.html                     # Template base report
‚îÇ   ‚îú‚îÄ‚îÄ sintesi.html                  # Tab sintesi
‚îÇ   ‚îú‚îÄ‚îÄ categoria.html                # Template categoria generica
‚îÇ   ‚îú‚îÄ‚îÄ leggibilita.html              # Report leggibilit√†
‚îÇ   ‚îî‚îÄ‚îÄ assets/
‚îÇ       ‚îú‚îÄ‚îÄ report.css                # Stili
‚îÇ       ‚îî‚îÄ‚îÄ report.js                 # JavaScript

data/
‚îú‚îÄ‚îÄ feedback.db                       # Database feedback (SQLite)
‚îú‚îÄ‚îÄ foreign_words/
‚îÇ   ‚îî‚îÄ‚îÄ common_foreign.json           # Parole straniere comuni
‚îî‚îÄ‚îÄ sensitive_words/
    ‚îî‚îÄ‚îÄ imbarazzanti.json             # Parole potenzialmente imbarazzanti

docs/
‚îî‚îÄ‚îÄ REPORT_SYSTEM_USAGE.md            # Guida utilizzo report
```

---

## üéØ Metriche di Successo

### Sprint 1
- ‚úÖ Report HTML generato per 100% dei documenti testati
- ‚úÖ Tutte le categorie base implementate (min 5)
- ‚úÖ Export funzionante
- ‚úÖ UI responsive su mobile/desktop

### Sprint 2
- ‚úÖ Analisi frase per frase accurata >95%
- ‚úÖ Report leggibilit√† comprensibile per utente non tecnico
- ‚úÖ Integrazione VdB funzionante
- ‚úÖ Performance accettabile (<10 sec per 5000 parole)

### Sprint 3
- ‚úÖ Falsi positivi ridotti del 30%+ grazie a lemmatizzazione
- ‚úÖ Tutte le 10 categorie implementate
- ‚úÖ Documentazione completa disponibile
- ‚úÖ Sistema pronto per produzione

### Sprint 4
- ‚úÖ Sistema feedback con >80% engagement utenti
- ‚úÖ Dizionario custom migliorato automaticamente
- ‚úÖ NER accuracy >85%
- ‚úÖ Dashboard statistiche completa

---

## üìù Note Implementative

### Priorit√† Features per Sprint 1
1. **Must Have**:
   - Tracking correzioni base
   - Report HTML sintesi
   - Tab errori riconosciuti
   - Export funzionante

2. **Should Have**:
   - Tab sconosciute
   - Tab sospette
   - Grafici base

3. **Nice to Have**:
   - Tutte le altre categorie
   - Animazioni CSS
   - Export PDF

### Considerazioni Performance
- **Caching**: Salvare report generati per evitare rielaborazioni
- **Lazy Loading**: Caricare tab solo quando selezionate
- **Batch Processing**: Per documenti grandi (>50k parole), dividere in chunk
- **Background Jobs**: Per elaborazioni lunghe, usare task queue (Celery)

### Compatibilit√† Browser
- Chrome/Edge: Full support
- Firefox: Full support
- Safari: Test required
- IE11: Non supportato (OK per progetto moderno)

---

## üöÄ Quick Start Post-Implementazione

### Generare Report Ortografia
```python
from correttore.core.correction_engine import CorrectionEngine
from correttore.utils.html_report_generator import generate_orthography_report

# Correggi documento
engine = CorrectionEngine()
result = engine.correct_document("input.docx")

# Genera report HTML
report_path = generate_orthography_report(
    result.corrections,
    output_path="outputs/report_ortografia.html"
)
```

### Generare Report Leggibilit√†
```python
from correttore.utils.readability_report_generator import generate_readability_report
from correttore.core.document_handler import DocumentHandler

# Carica documento
handler = DocumentHandler()
text = handler.extract_text("input.docx")

# Genera report
report_path = generate_readability_report(
    text,
    output_path="outputs/report_leggibilita.html",
    use_vocabulary=True
)
```

### Via Web Interface
```bash
# Avvia server
python -m correttore

# Upload documento su http://localhost:5000
# Clicca "Correggi Documento"
# Ricevi:
#   1. Documento corretto
#   2. Report Ortografia HTML
#   3. Report Leggibilit√† HTML (opzionale)
```

---

## üìû Supporto e Documentazione

- **Documentazione Tecnica**: `docs/REPORT_SYSTEM_USAGE.md`
- **API Reference**: Generata automaticamente con Sphinx
- **Examples**: `examples/generate_report_example.py`
- **Issue Tracking**: GitHub Issues

---

**Documento vivo**: Questo piano verr√† aggiornato durante l'implementazione con:
- ‚úÖ Checklist progressi
- üêõ Bug noti e workaround
- üí° Idee future
- üìà Metriche performance

---

*Ultima modifica: 24 Ottobre 2025*
